{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d29a7-90d0-4aea-a535-56f2ee26145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers accelerate datasets git+https://github.com/huggingface/diffusers Pillow==9.4.0 torchmetrics wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a076321-f9eb-4f7d-b3fd-a0b0b418d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from local_secrets import hf_token, wandb_key\n",
    "# from huggingface_hub import login\n",
    "# import wandb\n",
    "\n",
    "# login(token=hf_token)\n",
    "# wandb.login(key=wandb_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60395d2d-a5f3-432d-9d29-cc3e6adf8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F, random, wandb, time\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "from diffusers import AutoencoderDC, SanaTransformer2DModel\n",
    "from diffusers.schedulers import FlowMatchEulerDiscreteScheduler\n",
    "from transformers import AutoModel, AutoTokenizer, set_seed\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import latent_to_PIL, make_grid, encode_prompt, dcae_scalingf, pil_clipscore, cifar10_labels, free_memory\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539a7f32-9159-48ca-9706-5b0566415fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g/.local/lib/python3.10/site-packages/diffusers/configuration_utils.py:245: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a model, please use <class 'diffusers.models.transformers.sana_transformer.SanaTransformer2DModel'>.load_config(...) followed by <class 'diffusers.models.transformers.sana_transformer.SanaTransformer2DModel'>.from_config(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.bfloat16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "transformer = SanaTransformer2DModel.from_config(\"transformer_Sana-7L-MBERT_config.json\").to(device).to(dtype)\n",
    "text_encoder = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\", torch_dtype=dtype).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\", torch_dtype=dtype)\n",
    "\n",
    "model = \"Efficient-Large-Model/Sana_600M_1024px_diffusers\"\n",
    "dcae = AutoencoderDC.from_pretrained(model, subfolder=\"vae\", torch_dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239874e-8912-4d43-a18b-bc764091aecc",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e806441-ef9c-4d81-82b8-4eac53550669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'latent'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"g-ronimo/CIFAR10-128-latents_dc-ae-f32c32-sana-1.0\")\n",
    "ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abaa1267-d803-4833-ae1e-b07205b7150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2, torch.Size([1, 300, 768]), torch.Size([1, 300]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-encode all the labels\n",
    "labels = cifar10_labels\n",
    "labels_encoded={k: encode_prompt(labels[k], tokenizer, text_encoder) for k in labels}\n",
    "\n",
    "len(labels_encoded), len(labels_encoded[0]), labels_encoded[0][0].shape, labels_encoded[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3018cf-f8c3-4ed1-8c66-24644152b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " tensor(-0.2373, device='cuda:0', dtype=torch.bfloat16),\n",
       " torch.Size([2, 32, 4, 4]),\n",
       " torch.Size([2, 300, 768]),\n",
       " torch.Size([2, 300]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and test our collate fn\n",
    "def collate(items):\n",
    "    labels = [i[\"label\"] for i in items]\n",
    "    latents = torch.cat([torch.Tensor(i[\"latent\"]) for i in items]).to(dtype).to(device)\n",
    "    prompts_encoded = torch.cat([labels_encoded[label][0] for label in labels])\n",
    "    prompts_atnmask = torch.cat([labels_encoded[label][1] for label in labels])\n",
    "\n",
    "    return labels, latents, prompts_encoded, prompts_atnmask\n",
    "\n",
    "dataloader = DataLoader(ds[\"train\"], batch_size=2, shuffle=True, generator = torch.manual_seed(seed), collate_fn=collate)\n",
    "labels, latents, prompts_encoded, prompts_atnmask = next(iter(dataloader))\n",
    "len(labels), latents.mean(), latents.shape, prompts_encoded.shape, prompts_atnmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf26f893-d44c-4c59-8690-0254b230ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a test batch\n",
    "# testbatch = []\n",
    "# seen = {}\n",
    "\n",
    "# for i in range(100):\n",
    "#     item = ds[\"train\"][i]\n",
    "#     label, latent = item[\"label\"], item[\"latent\"]\n",
    "#     if not label in seen:\n",
    "#         print(\"Adding \", label)\n",
    "#         seen[label] = True\n",
    "#         testbatch.append(item)\n",
    "#     if len(testbatch) == 10: break\n",
    "# testbatch = collate(testbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6f2404-0b1a-4a41-a641-b0e2a0b1ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, latents, prompts_encoded, prompts_atnmask = testbatch\n",
    "\n",
    "# print(labels)\n",
    "# latents_decoded = [latent_to_PIL(latents[i,None], dcae) for i in range(len(labels))]\n",
    "# display(make_grid(latents_decoded, 2, 5).resize((800,300)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb384ce1-f799-4cdd-8b0e-82c6422abde6",
   "metadata": {},
   "source": [
    "# Helpers for eval and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9310e27-651b-424b-ae73-f9203875dc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, [1000, 666, 333])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_timesteps(num_steps):\n",
    "    dt = 1.0 / num_steps\n",
    "    timesteps = [int(i/num_steps*1000) for i in range(num_steps, 0, -1)]\n",
    "    return dt, timesteps\n",
    "get_timesteps(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3612ec36-fb6b-416b-ba05-c589bebf7324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(prompt, latent_dim=[1, 32, 4, 4], num_steps=100, latent_seed=42):\n",
    "    dt, timesteps = get_timesteps(num_steps)\n",
    "    # print(timesteps)\n",
    "    prompt_encoded, prompt_atnmask = encode_prompt(prompt, tokenizer, text_encoder)\n",
    "    latent = torch.randn(latent_dim, generator = torch.manual_seed(latent_seed)).to(dtype).to(device)\n",
    "    for t in timesteps:\n",
    "        t = torch.Tensor([t]).to(dtype).to(device)\n",
    "        with torch.no_grad():\n",
    "            noise_pred = transformer(latent, encoder_hidden_states=prompt_encoded, timestep=t, encoder_attention_mask=prompt_atnmask, return_dict=False)[0]\n",
    "        latent = latent - dt * noise_pred\n",
    "\n",
    "    return latent_to_PIL(latent / dcae_scalingf, dcae)\n",
    "\n",
    "generate(\"horse\", num_steps=10, latent_seed=43).resize((128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57074bb1-4138-486c-8063-dd57ac8dba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.755537974683544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_loss(data_val, batch_size=128, timesteps=1000):\n",
    "    losses = []\n",
    "    eval_dataloader = iter(DataLoader(data_val, batch_size=batch_size, shuffle=False, collate_fn=collate))\n",
    "\n",
    "    for batch_num, (labels, latents, prompts_encoded, prompts_atnmask) in tqdm(enumerate(eval_dataloader), \"eval_loss\"):\n",
    "        noise = torch.randn_like(latents)\n",
    "        t = torch.randint(1, timesteps + 1, (latents.size(0),)).to(device)\n",
    "        tperc = t.view([latents.size(0), *([1] * len(latents.shape[1:]))])/timesteps\n",
    "        latents_noisy = (1 - tperc) * latents + tperc * noise # (1-noise_level) * latent + noise_level * noise\n",
    "        latents_noisy = latents_noisy * dcae_scalingf\n",
    "        with torch.no_grad():\n",
    "            noise_pred = transformer(latents_noisy.to(dtype), prompts_encoded, t, prompts_atnmask).sample\n",
    "    \n",
    "        loss = F.mse_loss(noise_pred, noise - latents)\n",
    "        losses.append(loss.item())  \n",
    "    return sum(losses)/len(losses)\n",
    "\n",
    "eval_loss(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5748ec87-d482-49c0-bf22-c1336eb71584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.364389419555664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_clipscore(images):\n",
    "    prompts = [cifar10_labels[k] for k in cifar10_labels]\n",
    "    return pil_clipscore(images, prompts)\n",
    "\n",
    "images = [generate(p) for p in tqdm([cifar10_labels[k] for k in cifar10_labels], \"eval_images\")]\n",
    "eval_clipscore(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d9761-8eaa-4f23-bfad-cc5fa3ce923f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413d4b4c-1efe-48f6-b422-40340a4718e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 156.41M\n",
      "2 splits: ['train', 'test'] [50000, 10000]\n"
     ]
    }
   ],
   "source": [
    "log_wandb = True\n",
    "lr = 5e-4\n",
    "# bs = 64\n",
    "bs = 384\n",
    "epochs = 1000\n",
    "timesteps_training = 1000\n",
    "steps_log, steps_eval = 40, 400\n",
    "# steps_log, steps_eval = 10, 20\n",
    "\n",
    "splits = list(ds.keys())\n",
    "data_train, data_val = ds[splits[0]], ds[splits[1]]\n",
    "\n",
    "steps_epoch = len(data_train) // bs\n",
    "\n",
    "dataloader = DataLoader(data_train, batch_size=bs, shuffle=True, generator = torch.manual_seed(seed), collate_fn=collate)\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=lr)\n",
    "\n",
    "model_size = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n",
    "print(f\"Model parameters: {model_size / 1e6:.2f}M\")\n",
    "print(f\"{len(splits)} splits: {splits}\", [len(ds[s]) for s in splits])\n",
    "assert len(splits)==2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1815d77d-33fd-40f2-aba1-08f28d8adce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mg-ronimo\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/g/jupyter/2025-02-04_Hana-Alpha14-CIFAR10-128/wandb/run-20250204_215827-18gkqzkk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g-ronimo/Hana/runs/18gkqzkk' target=\"_blank\">Z-156.41M_CIFAR10-128_LR-0.0005_BS-384_TS-1000_my3090</a></strong> to <a href='https://wandb.ai/g-ronimo/Hana' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g-ronimo/Hana' target=\"_blank\">https://wandb.ai/g-ronimo/Hana</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g-ronimo/Hana/runs/18gkqzkk' target=\"_blank\">https://wandb.ai/g-ronimo/Hana/runs/18gkqzkk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, epoch: 0.0000, train loss: 6.7188, grad_norm: 20.00, 20.32ms/step, 18893.02samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.75it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, eval loss: 11.6915, clipscore: 23.88\n",
      "step 40, epoch: 0.3077, train loss: 4.3438, grad_norm: 1.90, 1155.15ms/step, 332.42samples/sec\n",
      "step 80, epoch: 0.6154, train loss: 3.3594, grad_norm: 1.24, 568.91ms/step, 674.97samples/sec\n",
      "step 120, epoch: 0.9231, train loss: 3.1562, grad_norm: 0.89, 581.78ms/step, 660.04samples/sec\n",
      "step 160, epoch: 1.2308, train loss: 3.1562, grad_norm: 0.82, 566.13ms/step, 678.29samples/sec\n",
      "step 200, epoch: 1.5385, train loss: 2.9844, grad_norm: 0.71, 577.88ms/step, 664.49samples/sec\n",
      "step 240, epoch: 1.8462, train loss: 2.9531, grad_norm: 0.67, 574.29ms/step, 668.65samples/sec\n",
      "step 280, epoch: 2.1538, train loss: 2.8438, grad_norm: 0.59, 565.70ms/step, 678.81samples/sec\n",
      "step 320, epoch: 2.4615, train loss: 2.9375, grad_norm: 0.69, 602.08ms/step, 637.79samples/sec\n",
      "step 360, epoch: 2.7692, train loss: 3.0000, grad_norm: 0.62, 592.91ms/step, 647.66samples/sec\n",
      "step 400, epoch: 3.0769, train loss: 2.8906, grad_norm: 0.62, 596.38ms/step, 643.88samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.59it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 400, eval loss: 2.8892, clipscore: 23.90\n",
      "step 440, epoch: 3.3846, train loss: 2.8438, grad_norm: 0.52, 1152.00ms/step, 333.33samples/sec\n",
      "step 480, epoch: 3.6923, train loss: 2.7500, grad_norm: 0.57, 589.87ms/step, 650.99samples/sec\n",
      "step 520, epoch: 4.0000, train loss: 2.8594, grad_norm: 0.54, 600.11ms/step, 639.89samples/sec\n",
      "step 560, epoch: 4.3077, train loss: 2.9844, grad_norm: 0.58, 586.09ms/step, 655.19samples/sec\n",
      "step 600, epoch: 4.6154, train loss: 2.8750, grad_norm: 0.57, 598.94ms/step, 641.13samples/sec\n",
      "step 640, epoch: 4.9231, train loss: 2.8281, grad_norm: 0.52, 591.57ms/step, 649.12samples/sec\n",
      "step 680, epoch: 5.2308, train loss: 2.8594, grad_norm: 0.59, 597.22ms/step, 642.98samples/sec\n",
      "step 720, epoch: 5.5385, train loss: 2.8125, grad_norm: 0.55, 591.98ms/step, 648.67samples/sec\n",
      "step 760, epoch: 5.8462, train loss: 2.8906, grad_norm: 0.49, 600.87ms/step, 639.08samples/sec\n",
      "step 800, epoch: 6.1538, train loss: 2.8281, grad_norm: 0.52, 584.35ms/step, 657.14samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:11,  7.17it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 800, eval loss: 2.8214, clipscore: 23.73\n",
      "step 840, epoch: 6.4615, train loss: 2.7969, grad_norm: 0.51, 1161.80ms/step, 330.52samples/sec\n",
      "step 880, epoch: 6.7692, train loss: 2.7656, grad_norm: 0.50, 602.62ms/step, 637.22samples/sec\n",
      "step 920, epoch: 7.0769, train loss: 2.8906, grad_norm: 0.52, 582.72ms/step, 658.98samples/sec\n",
      "step 960, epoch: 7.3846, train loss: 2.9219, grad_norm: 0.46, 601.66ms/step, 638.23samples/sec\n",
      "step 1000, epoch: 7.6923, train loss: 2.8125, grad_norm: 0.48, 584.11ms/step, 657.41samples/sec\n",
      "step 1040, epoch: 8.0000, train loss: 2.7812, grad_norm: 0.53, 590.99ms/step, 649.76samples/sec\n",
      "step 1080, epoch: 8.3077, train loss: 2.7344, grad_norm: 0.48, 586.44ms/step, 654.80samples/sec\n",
      "step 1120, epoch: 8.6154, train loss: 2.7812, grad_norm: 0.45, 602.24ms/step, 637.62samples/sec\n",
      "step 1160, epoch: 8.9231, train loss: 2.8750, grad_norm: 0.44, 600.81ms/step, 639.14samples/sec\n",
      "step 1200, epoch: 9.2308, train loss: 2.8594, grad_norm: 0.44, 585.88ms/step, 655.42samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.50it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1200, eval loss: 2.8006, clipscore: 23.98\n",
      "step 1240, epoch: 9.5385, train loss: 2.7188, grad_norm: 0.47, 1130.43ms/step, 339.69samples/sec\n",
      "step 1280, epoch: 9.8462, train loss: 2.7188, grad_norm: 0.49, 575.46ms/step, 667.29samples/sec\n",
      "step 1320, epoch: 10.1538, train loss: 2.8750, grad_norm: 0.48, 565.69ms/step, 678.82samples/sec\n",
      "step 1360, epoch: 10.4615, train loss: 2.8438, grad_norm: 0.46, 571.64ms/step, 671.75samples/sec\n",
      "step 1400, epoch: 10.7692, train loss: 2.7500, grad_norm: 0.43, 580.46ms/step, 661.54samples/sec\n",
      "step 1440, epoch: 11.0769, train loss: 2.6562, grad_norm: 0.77, 561.21ms/step, 684.24samples/sec\n",
      "step 1480, epoch: 11.3846, train loss: 2.7188, grad_norm: 0.48, 578.96ms/step, 663.26samples/sec\n",
      "step 1520, epoch: 11.6923, train loss: 2.7656, grad_norm: 0.42, 577.84ms/step, 664.55samples/sec\n",
      "step 1560, epoch: 12.0000, train loss: 2.8438, grad_norm: 0.42, 572.90ms/step, 670.28samples/sec\n",
      "step 1600, epoch: 12.3077, train loss: 2.7969, grad_norm: 0.41, 577.95ms/step, 664.42samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.60it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1600, eval loss: 2.7852, clipscore: 24.22\n",
      "step 1640, epoch: 12.6154, train loss: 2.7344, grad_norm: 0.47, 1139.79ms/step, 336.90samples/sec\n",
      "step 1680, epoch: 12.9231, train loss: 2.7188, grad_norm: 0.48, 570.49ms/step, 673.11samples/sec\n",
      "step 1720, epoch: 13.2308, train loss: 2.8594, grad_norm: 0.48, 563.63ms/step, 681.29samples/sec\n",
      "step 1760, epoch: 13.5385, train loss: 2.8906, grad_norm: 0.41, 597.12ms/step, 643.09samples/sec\n",
      "step 1800, epoch: 13.8462, train loss: 2.7812, grad_norm: 0.45, 577.18ms/step, 665.31samples/sec\n",
      "step 1840, epoch: 14.1538, train loss: 2.7344, grad_norm: 0.44, 566.93ms/step, 677.33samples/sec\n",
      "step 1880, epoch: 14.4615, train loss: 2.7031, grad_norm: 0.40, 576.32ms/step, 666.30samples/sec\n",
      "step 1920, epoch: 14.7692, train loss: 2.7500, grad_norm: 0.41, 570.51ms/step, 673.08samples/sec\n",
      "step 1960, epoch: 15.0769, train loss: 2.8125, grad_norm: 0.42, 583.50ms/step, 658.10samples/sec\n",
      "step 2000, epoch: 15.3846, train loss: 2.7656, grad_norm: 0.41, 567.16ms/step, 677.06samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.55it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, eval loss: 2.7714, clipscore: 24.29\n",
      "step 2040, epoch: 15.6923, train loss: 2.7031, grad_norm: 0.47, 1128.13ms/step, 340.39samples/sec\n",
      "step 2080, epoch: 16.0000, train loss: 2.7188, grad_norm: 0.46, 575.85ms/step, 666.84samples/sec\n",
      "step 2120, epoch: 16.3077, train loss: 2.8281, grad_norm: 0.52, 563.92ms/step, 680.95samples/sec\n",
      "step 2160, epoch: 16.6154, train loss: 2.8750, grad_norm: 0.44, 575.19ms/step, 667.61samples/sec\n",
      "step 2200, epoch: 16.9231, train loss: 2.7812, grad_norm: 0.41, 568.84ms/step, 675.06samples/sec\n",
      "step 2240, epoch: 17.2308, train loss: 2.7344, grad_norm: 0.38, 573.05ms/step, 670.10samples/sec\n",
      "step 2280, epoch: 17.5385, train loss: 2.6719, grad_norm: 0.44, 570.72ms/step, 672.84samples/sec\n",
      "step 2320, epoch: 17.8462, train loss: 2.7656, grad_norm: 0.44, 574.76ms/step, 668.10samples/sec\n",
      "step 2360, epoch: 18.1538, train loss: 2.7188, grad_norm: 0.43, 559.79ms/step, 685.97samples/sec\n",
      "step 2400, epoch: 18.4615, train loss: 2.7656, grad_norm: 0.40, 578.55ms/step, 663.73samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.76it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2400, eval loss: 2.7654, clipscore: 24.13\n",
      "step 2440, epoch: 18.7692, train loss: 2.6875, grad_norm: 0.41, 1130.68ms/step, 339.62samples/sec\n",
      "step 2480, epoch: 19.0769, train loss: 2.6719, grad_norm: 0.48, 575.65ms/step, 667.07samples/sec\n",
      "step 2520, epoch: 19.3846, train loss: 2.8438, grad_norm: 0.40, 563.15ms/step, 681.88samples/sec\n",
      "step 2560, epoch: 19.6923, train loss: 2.8438, grad_norm: 0.38, 577.19ms/step, 665.29samples/sec\n",
      "step 2600, epoch: 20.0000, train loss: 2.7344, grad_norm: 0.40, 570.44ms/step, 673.16samples/sec\n",
      "step 2640, epoch: 20.3077, train loss: 2.7656, grad_norm: 0.40, 569.89ms/step, 673.82samples/sec\n",
      "step 2680, epoch: 20.6154, train loss: 2.6875, grad_norm: 0.39, 569.87ms/step, 673.84samples/sec\n",
      "step 2720, epoch: 20.9231, train loss: 2.7031, grad_norm: 0.42, 577.79ms/step, 664.61samples/sec\n",
      "step 2760, epoch: 21.2308, train loss: 2.7188, grad_norm: 0.41, 563.16ms/step, 681.87samples/sec\n",
      "step 2800, epoch: 21.5385, train loss: 2.7500, grad_norm: 0.37, 575.52ms/step, 667.22samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.84it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2800, eval loss: 2.7585, clipscore: 23.58\n",
      "step 2840, epoch: 21.8462, train loss: 2.6562, grad_norm: 0.38, 1136.74ms/step, 337.81samples/sec\n",
      "step 2880, epoch: 22.1538, train loss: 2.6562, grad_norm: 0.40, 592.44ms/step, 648.17samples/sec\n",
      "step 2920, epoch: 22.4615, train loss: 2.7656, grad_norm: 0.39, 593.17ms/step, 647.37samples/sec\n",
      "step 2960, epoch: 22.7692, train loss: 2.8438, grad_norm: 0.42, 587.68ms/step, 653.42samples/sec\n",
      "step 3000, epoch: 23.0769, train loss: 2.6875, grad_norm: 0.40, 578.66ms/step, 663.60samples/sec\n",
      "step 3040, epoch: 23.3846, train loss: 2.7344, grad_norm: 0.41, 565.77ms/step, 678.72samples/sec\n",
      "step 3080, epoch: 23.6923, train loss: 2.6562, grad_norm: 0.36, 575.59ms/step, 667.14samples/sec\n",
      "step 3120, epoch: 24.0000, train loss: 2.7031, grad_norm: 0.40, 570.45ms/step, 673.16samples/sec\n",
      "step 3160, epoch: 24.3077, train loss: 2.7188, grad_norm: 0.42, 569.87ms/step, 673.84samples/sec\n",
      "step 3200, epoch: 24.6154, train loss: 2.7500, grad_norm: 0.36, 570.21ms/step, 673.44samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.60it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3200, eval loss: 2.7559, clipscore: 24.98\n",
      "step 3240, epoch: 24.9231, train loss: 2.7344, grad_norm: 0.41, 1114.03ms/step, 344.70samples/sec\n",
      "step 3440, epoch: 26.4615, train loss: 2.7344, grad_norm: 0.40, 573.88ms/step, 669.13samples/sec\n",
      "step 3480, epoch: 26.7692, train loss: 2.6719, grad_norm: 0.41, 574.06ms/step, 668.91samples/sec\n",
      "step 3520, epoch: 27.0769, train loss: 2.7031, grad_norm: 0.39, 579.15ms/step, 663.05samples/sec\n",
      "step 3560, epoch: 27.3846, train loss: 2.7188, grad_norm: 0.42, 563.21ms/step, 681.80samples/sec\n",
      "step 3600, epoch: 27.6923, train loss: 2.7500, grad_norm: 0.37, 578.93ms/step, 663.29samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.83it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3600, eval loss: 2.7540, clipscore: 23.66\n",
      "step 3640, epoch: 28.0000, train loss: 2.6562, grad_norm: 0.38, 1191.17ms/step, 322.37samples/sec\n",
      "step 3680, epoch: 28.3077, train loss: 2.7656, grad_norm: 0.39, 588.26ms/step, 652.77samples/sec\n",
      "step 3720, epoch: 28.6154, train loss: 2.7969, grad_norm: 0.45, 590.40ms/step, 650.41samples/sec\n",
      "step 3760, epoch: 28.9231, train loss: 2.8125, grad_norm: 0.38, 569.54ms/step, 674.23samples/sec\n",
      "step 3800, epoch: 29.2308, train loss: 2.7656, grad_norm: 0.40, 575.04ms/step, 667.78samples/sec\n",
      "step 3840, epoch: 29.5385, train loss: 2.7500, grad_norm: 0.38, 598.57ms/step, 641.53samples/sec\n",
      "step 3880, epoch: 29.8462, train loss: 2.6406, grad_norm: 0.39, 592.69ms/step, 647.89samples/sec\n",
      "step 3920, epoch: 30.1538, train loss: 2.6875, grad_norm: 0.37, 600.40ms/step, 639.57samples/sec\n",
      "step 3960, epoch: 30.4615, train loss: 2.6719, grad_norm: 0.36, 584.95ms/step, 656.47samples/sec\n",
      "step 4000, epoch: 30.7692, train loss: 2.7500, grad_norm: 0.38, 583.97ms/step, 657.57samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.84it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000, eval loss: 2.7538, clipscore: 24.45\n",
      "step 4040, epoch: 31.0769, train loss: 2.6250, grad_norm: 0.42, 1132.82ms/step, 338.98samples/sec\n",
      "step 4080, epoch: 31.3846, train loss: 2.7969, grad_norm: 0.44, 594.36ms/step, 646.07samples/sec\n",
      "step 4120, epoch: 31.6923, train loss: 2.7656, grad_norm: 0.38, 591.29ms/step, 649.42samples/sec\n",
      "step 4160, epoch: 32.0000, train loss: 2.7969, grad_norm: 0.38, 603.25ms/step, 636.55samples/sec\n",
      "step 4200, epoch: 32.3077, train loss: 2.7656, grad_norm: 0.41, 588.77ms/step, 652.21samples/sec\n",
      "step 4240, epoch: 32.6154, train loss: 2.6875, grad_norm: 0.38, 602.05ms/step, 637.82samples/sec\n",
      "step 4280, epoch: 32.9231, train loss: 2.6562, grad_norm: 0.35, 599.56ms/step, 640.47samples/sec\n",
      "step 4320, epoch: 33.2308, train loss: 2.7031, grad_norm: 0.38, 573.89ms/step, 669.12samples/sec\n",
      "step 4360, epoch: 33.5385, train loss: 2.6719, grad_norm: 0.35, 572.57ms/step, 670.66samples/sec\n",
      "step 4400, epoch: 33.8462, train loss: 2.7031, grad_norm: 0.38, 571.72ms/step, 671.65samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.23it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4400, eval loss: 2.7559, clipscore: 24.71\n",
      "step 4440, epoch: 34.1538, train loss: 2.6250, grad_norm: 0.38, 1143.63ms/step, 335.77samples/sec\n",
      "step 4480, epoch: 34.4615, train loss: 2.7344, grad_norm: 0.42, 593.66ms/step, 646.84samples/sec\n",
      "step 4520, epoch: 34.7692, train loss: 2.7500, grad_norm: 0.37, 591.20ms/step, 649.52samples/sec\n",
      "step 4560, epoch: 35.0769, train loss: 2.7500, grad_norm: 0.38, 598.99ms/step, 641.08samples/sec\n",
      "step 4600, epoch: 35.3846, train loss: 2.7656, grad_norm: 0.39, 590.27ms/step, 650.54samples/sec\n",
      "step 4640, epoch: 35.6923, train loss: 2.6875, grad_norm: 0.35, 594.51ms/step, 645.92samples/sec\n",
      "step 4680, epoch: 36.0000, train loss: 2.6562, grad_norm: 0.35, 592.92ms/step, 647.64samples/sec\n",
      "step 4720, epoch: 36.3077, train loss: 2.6406, grad_norm: 0.41, 593.97ms/step, 646.50samples/sec\n",
      "step 4760, epoch: 36.6154, train loss: 2.6562, grad_norm: 0.40, 591.55ms/step, 649.14samples/sec\n",
      "step 4800, epoch: 36.9231, train loss: 2.7188, grad_norm: 0.39, 603.67ms/step, 636.11samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.41it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4800, eval loss: 2.7510, clipscore: 23.50\n",
      "step 4840, epoch: 37.2308, train loss: 2.6250, grad_norm: 0.35, 1129.83ms/step, 339.87samples/sec\n",
      "step 4880, epoch: 37.5385, train loss: 2.7344, grad_norm: 0.37, 562.52ms/step, 682.64samples/sec\n",
      "step 4920, epoch: 37.8462, train loss: 2.7500, grad_norm: 0.41, 575.77ms/step, 666.93samples/sec\n",
      "step 4960, epoch: 38.1538, train loss: 2.7656, grad_norm: 0.40, 570.60ms/step, 672.98samples/sec\n",
      "step 5000, epoch: 38.4615, train loss: 2.7656, grad_norm: 0.38, 574.34ms/step, 668.60samples/sec\n",
      "step 5040, epoch: 38.7692, train loss: 2.6875, grad_norm: 0.40, 570.47ms/step, 673.13samples/sec\n",
      "step 5080, epoch: 39.0769, train loss: 2.6094, grad_norm: 0.35, 577.78ms/step, 664.61samples/sec\n",
      "step 5120, epoch: 39.3846, train loss: 2.6094, grad_norm: 0.38, 564.17ms/step, 680.64samples/sec\n",
      "step 5160, epoch: 39.6923, train loss: 2.6562, grad_norm: 0.39, 577.86ms/step, 664.52samples/sec\n",
      "step 5200, epoch: 40.0000, train loss: 2.7031, grad_norm: 0.35, 579.41ms/step, 662.75samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.79it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5200, eval loss: 2.7544, clipscore: 23.21\n",
      "step 5240, epoch: 40.3077, train loss: 2.7656, grad_norm: 0.47, 1138.39ms/step, 337.32samples/sec\n",
      "step 5280, epoch: 40.6154, train loss: 2.7344, grad_norm: 0.36, 577.68ms/step, 664.73samples/sec\n",
      "step 5320, epoch: 40.9231, train loss: 2.7500, grad_norm: 0.37, 572.73ms/step, 670.47samples/sec\n",
      "step 5360, epoch: 41.2308, train loss: 2.7812, grad_norm: 0.40, 587.55ms/step, 653.57samples/sec\n",
      "step 5400, epoch: 41.5385, train loss: 2.7344, grad_norm: 0.38, 572.01ms/step, 671.32samples/sec\n",
      "step 5440, epoch: 41.8462, train loss: 2.6250, grad_norm: 0.37, 579.84ms/step, 662.25samples/sec\n",
      "step 5480, epoch: 42.1538, train loss: 2.6562, grad_norm: 0.32, 576.98ms/step, 665.54samples/sec\n",
      "step 5520, epoch: 42.4615, train loss: 2.6094, grad_norm: 0.36, 565.75ms/step, 678.74samples/sec\n",
      "step 5560, epoch: 42.7692, train loss: 2.6406, grad_norm: 0.42, 576.43ms/step, 666.17samples/sec\n",
      "step 5600, epoch: 43.0769, train loss: 2.7188, grad_norm: 0.38, 570.25ms/step, 673.38samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.61it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5600, eval loss: 2.7555, clipscore: 23.80\n",
      "step 5640, epoch: 43.3846, train loss: 2.7969, grad_norm: 0.42, 1133.93ms/step, 338.65samples/sec\n",
      "step 5680, epoch: 43.6923, train loss: 2.7969, grad_norm: 0.43, 599.03ms/step, 641.03samples/sec\n",
      "step 5720, epoch: 44.0000, train loss: 2.7500, grad_norm: 0.36, 588.05ms/step, 653.00samples/sec\n",
      "step 5760, epoch: 44.3077, train loss: 2.8438, grad_norm: 0.38, 577.78ms/step, 664.62samples/sec\n",
      "step 5800, epoch: 44.6154, train loss: 2.7344, grad_norm: 0.36, 565.80ms/step, 678.68samples/sec\n",
      "step 5840, epoch: 44.9231, train loss: 2.7188, grad_norm: 0.39, 576.70ms/step, 665.86samples/sec\n",
      "step 5880, epoch: 45.2308, train loss: 2.6406, grad_norm: 0.35, 570.52ms/step, 673.07samples/sec\n",
      "step 5920, epoch: 45.5385, train loss: 2.5781, grad_norm: 0.37, 567.69ms/step, 676.43samples/sec\n",
      "step 5960, epoch: 45.8462, train loss: 2.6562, grad_norm: 0.38, 569.87ms/step, 673.83samples/sec\n",
      "step 6000, epoch: 46.1538, train loss: 2.7031, grad_norm: 0.34, 583.20ms/step, 658.43samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.72it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000, eval loss: 2.7526, clipscore: 23.64\n",
      "step 6040, epoch: 46.4615, train loss: 2.8125, grad_norm: 0.38, 1157.57ms/step, 331.73samples/sec\n",
      "step 6080, epoch: 46.7692, train loss: 2.7031, grad_norm: 0.37, 595.94ms/step, 644.36samples/sec\n",
      "step 6120, epoch: 47.0769, train loss: 2.7500, grad_norm: 0.35, 604.74ms/step, 634.98samples/sec\n",
      "step 6160, epoch: 47.3846, train loss: 2.6719, grad_norm: 0.44, 589.42ms/step, 651.48samples/sec\n",
      "step 6200, epoch: 47.6923, train loss: 2.7344, grad_norm: 0.36, 604.66ms/step, 635.06samples/sec\n",
      "step 6240, epoch: 48.0000, train loss: 2.6094, grad_norm: 0.40, 592.46ms/step, 648.14samples/sec\n",
      "step 6280, epoch: 48.3077, train loss: 2.5781, grad_norm: 0.37, 605.55ms/step, 634.13samples/sec\n",
      "step 6320, epoch: 48.6154, train loss: 2.5625, grad_norm: 0.44, 586.94ms/step, 654.24samples/sec\n",
      "step 6360, epoch: 48.9231, train loss: 2.6562, grad_norm: 0.39, 586.76ms/step, 654.44samples/sec\n",
      "step 6400, epoch: 49.2308, train loss: 2.7031, grad_norm: 0.37, 576.53ms/step, 666.06samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.69it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6400, eval loss: 2.7516, clipscore: 24.64\n",
      "step 6440, epoch: 49.5385, train loss: 2.7188, grad_norm: 0.35, 1114.12ms/step, 344.67samples/sec\n",
      "step 6480, epoch: 49.8462, train loss: 2.7500, grad_norm: 0.41, 581.45ms/step, 660.42samples/sec\n",
      "step 6520, epoch: 50.1538, train loss: 2.7188, grad_norm: 0.38, 577.05ms/step, 665.46samples/sec\n",
      "step 6560, epoch: 50.4615, train loss: 2.6875, grad_norm: 0.36, 570.05ms/step, 673.63samples/sec\n",
      "step 6600, epoch: 50.7692, train loss: 2.7188, grad_norm: 0.37, 580.61ms/step, 661.37samples/sec\n",
      "step 6640, epoch: 51.0769, train loss: 2.7188, grad_norm: 0.38, 572.01ms/step, 671.32samples/sec\n",
      "step 6680, epoch: 51.3846, train loss: 2.5625, grad_norm: 0.83, 570.22ms/step, 673.43samples/sec\n",
      "step 6720, epoch: 51.6923, train loss: 2.5781, grad_norm: 0.36, 572.37ms/step, 670.89samples/sec\n",
      "step 6760, epoch: 52.0000, train loss: 2.7031, grad_norm: 0.40, 580.06ms/step, 662.00samples/sec\n",
      "step 6800, epoch: 52.3077, train loss: 2.6562, grad_norm: 0.38, 577.26ms/step, 665.21samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.80it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6800, eval loss: 2.7553, clipscore: 24.11\n",
      "step 6840, epoch: 52.6154, train loss: 2.7500, grad_norm: 0.38, 1137.93ms/step, 337.45samples/sec\n",
      "step 6880, epoch: 52.9231, train loss: 2.7500, grad_norm: 0.41, 580.68ms/step, 661.29samples/sec\n",
      "step 6920, epoch: 53.2308, train loss: 2.6875, grad_norm: 0.37, 570.22ms/step, 673.43samples/sec\n",
      "step 6960, epoch: 53.5385, train loss: 2.6719, grad_norm: 0.36, 573.25ms/step, 669.86samples/sec\n",
      "step 7000, epoch: 53.8462, train loss: 2.7188, grad_norm: 0.37, 571.38ms/step, 672.06samples/sec\n",
      "step 7040, epoch: 54.1538, train loss: 2.6562, grad_norm: 0.36, 581.16ms/step, 660.74samples/sec\n",
      "step 7080, epoch: 54.4615, train loss: 2.7188, grad_norm: 0.40, 565.06ms/step, 679.58samples/sec\n",
      "step 7120, epoch: 54.7692, train loss: 2.5938, grad_norm: 0.35, 580.58ms/step, 661.41samples/sec\n",
      "step 7160, epoch: 55.0769, train loss: 2.6562, grad_norm: 0.36, 577.71ms/step, 664.69samples/sec\n",
      "step 7200, epoch: 55.3846, train loss: 2.7031, grad_norm: 0.36, 572.20ms/step, 671.09samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.58it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7200, eval loss: 2.7601, clipscore: 23.21\n",
      "step 7240, epoch: 55.6923, train loss: 2.7500, grad_norm: 0.35, 1118.72ms/step, 343.25samples/sec\n",
      "step 7280, epoch: 56.0000, train loss: 2.6719, grad_norm: 0.37, 576.26ms/step, 666.37samples/sec\n",
      "step 7320, epoch: 56.3077, train loss: 2.7500, grad_norm: 0.42, 570.03ms/step, 673.65samples/sec\n",
      "step 7360, epoch: 56.6154, train loss: 2.6719, grad_norm: 0.44, 572.25ms/step, 671.04samples/sec\n",
      "step 7400, epoch: 56.9231, train loss: 2.7656, grad_norm: 0.38, 570.76ms/step, 672.79samples/sec\n",
      "step 7440, epoch: 57.2308, train loss: 2.6406, grad_norm: 0.36, 580.26ms/step, 661.77samples/sec\n",
      "step 7480, epoch: 57.5385, train loss: 2.6094, grad_norm: 0.35, 565.18ms/step, 679.42samples/sec\n",
      "step 7520, epoch: 57.8462, train loss: 2.5469, grad_norm: 0.35, 576.38ms/step, 666.23samples/sec\n",
      "step 7560, epoch: 58.1538, train loss: 2.6406, grad_norm: 0.38, 572.38ms/step, 670.89samples/sec\n",
      "step 7600, epoch: 58.4615, train loss: 2.7656, grad_norm: 0.40, 582.79ms/step, 658.90samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.75it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7600, eval loss: 2.7704, clipscore: 23.52\n",
      "step 7640, epoch: 58.7692, train loss: 2.6094, grad_norm: 0.34, 1121.38ms/step, 342.44samples/sec\n",
      "step 7680, epoch: 59.0769, train loss: 2.5469, grad_norm: 0.35, 571.23ms/step, 672.23samples/sec\n",
      "step 7720, epoch: 59.3846, train loss: 2.6250, grad_norm: 0.33, 579.02ms/step, 663.19samples/sec\n",
      "step 7760, epoch: 59.6923, train loss: 2.7344, grad_norm: 0.40, 564.34ms/step, 680.43samples/sec\n",
      "step 7800, epoch: 60.0000, train loss: 2.6250, grad_norm: 0.36, 580.61ms/step, 661.37samples/sec\n",
      "step 7840, epoch: 60.3077, train loss: 2.6250, grad_norm: 0.37, 570.07ms/step, 673.61samples/sec\n",
      "step 7880, epoch: 60.6154, train loss: 2.5938, grad_norm: 0.35, 571.78ms/step, 671.59samples/sec\n",
      "step 7920, epoch: 60.9231, train loss: 2.6250, grad_norm: 0.37, 576.64ms/step, 665.93samples/sec\n",
      "step 7960, epoch: 61.2308, train loss: 2.7656, grad_norm: 0.41, 571.01ms/step, 672.50samples/sec\n",
      "step 8000, epoch: 61.5385, train loss: 2.6719, grad_norm: 0.37, 564.77ms/step, 679.93samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.53it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000, eval loss: 2.7534, clipscore: 24.36\n",
      "step 8040, epoch: 61.8462, train loss: 2.5938, grad_norm: 0.38, 1139.77ms/step, 336.91samples/sec\n",
      "step 8080, epoch: 62.1538, train loss: 2.5312, grad_norm: 0.37, 579.06ms/step, 663.14samples/sec\n",
      "step 8120, epoch: 62.4615, train loss: 2.6562, grad_norm: 0.34, 576.41ms/step, 666.19samples/sec\n",
      "step 8160, epoch: 62.7692, train loss: 2.7656, grad_norm: 0.39, 575.47ms/step, 667.27samples/sec\n",
      "step 8200, epoch: 63.0769, train loss: 2.6250, grad_norm: 0.33, 579.52ms/step, 662.62samples/sec\n",
      "step 8240, epoch: 63.3846, train loss: 2.6719, grad_norm: 0.38, 579.22ms/step, 662.96samples/sec\n",
      "step 8280, epoch: 63.6923, train loss: 2.5938, grad_norm: 0.39, 563.56ms/step, 681.38samples/sec\n",
      "step 8320, epoch: 64.0000, train loss: 2.6719, grad_norm: 0.40, 579.84ms/step, 662.25samples/sec\n",
      "step 8360, epoch: 64.3077, train loss: 2.7031, grad_norm: 0.39, 576.21ms/step, 666.43samples/sec\n",
      "step 8400, epoch: 64.6154, train loss: 2.6250, grad_norm: 0.40, 563.98ms/step, 680.88samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.80it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8400, eval loss: 2.7629, clipscore: 23.85\n",
      "step 8440, epoch: 64.9231, train loss: 2.6250, grad_norm: 0.40, 1125.23ms/step, 341.26samples/sec\n",
      "step 8480, epoch: 65.2308, train loss: 2.5625, grad_norm: 0.36, 568.95ms/step, 674.93samples/sec\n",
      "step 8520, epoch: 65.5385, train loss: 2.6875, grad_norm: 0.36, 573.45ms/step, 669.63samples/sec\n",
      "step 8560, epoch: 65.8462, train loss: 2.7188, grad_norm: 0.39, 570.54ms/step, 673.04samples/sec\n",
      "step 8600, epoch: 66.1538, train loss: 2.6406, grad_norm: 0.34, 579.77ms/step, 662.33samples/sec\n",
      "step 8640, epoch: 66.4615, train loss: 2.6562, grad_norm: 0.37, 577.11ms/step, 665.39samples/sec\n",
      "step 8680, epoch: 66.7692, train loss: 2.5469, grad_norm: 0.36, 563.03ms/step, 682.02samples/sec\n",
      "step 8720, epoch: 67.0769, train loss: 2.6094, grad_norm: 0.39, 570.56ms/step, 673.03samples/sec\n",
      "step 8760, epoch: 67.3846, train loss: 2.7344, grad_norm: 0.36, 578.71ms/step, 663.54samples/sec\n",
      "step 8800, epoch: 67.6923, train loss: 2.6562, grad_norm: 0.37, 569.30ms/step, 674.51samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:10,  7.86it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8800, eval loss: 2.7712, clipscore: 24.03\n",
      "step 8840, epoch: 68.0000, train loss: 2.6094, grad_norm: 0.33, 1142.32ms/step, 336.16samples/sec\n",
      "step 8880, epoch: 68.3077, train loss: 2.5781, grad_norm: 0.37, 589.22ms/step, 651.71samples/sec\n",
      "step 8920, epoch: 68.6154, train loss: 2.6875, grad_norm: 0.39, 588.11ms/step, 652.94samples/sec\n",
      "step 8960, epoch: 68.9231, train loss: 2.7188, grad_norm: 0.38, 603.23ms/step, 636.58samples/sec\n",
      "step 9000, epoch: 69.2308, train loss: 2.6250, grad_norm: 0.33, 601.81ms/step, 638.07samples/sec\n",
      "step 9040, epoch: 69.5385, train loss: 2.6719, grad_norm: 0.42, 586.66ms/step, 654.56samples/sec\n",
      "step 9080, epoch: 69.8462, train loss: 2.5312, grad_norm: 0.38, 602.38ms/step, 637.47samples/sec\n",
      "step 9120, epoch: 70.1538, train loss: 2.6406, grad_norm: 0.38, 593.03ms/step, 647.52samples/sec\n",
      "step 9160, epoch: 70.4615, train loss: 2.7031, grad_norm: 0.38, 600.09ms/step, 639.90samples/sec\n",
      "step 9200, epoch: 70.7692, train loss: 2.6250, grad_norm: 0.38, 586.24ms/step, 655.03samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_loss: 79it [00:11,  7.15it/s]\n",
      "eval_images: 100%|██████████████████████████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9200, eval loss: 2.7682, clipscore: 24.20\n",
      "step 9240, epoch: 71.0769, train loss: 2.6094, grad_norm: 0.35, 1150.15ms/step, 333.87samples/sec\n",
      "step 9280, epoch: 71.3846, train loss: 2.5781, grad_norm: 0.39, 577.89ms/step, 664.49samples/sec\n",
      "step 9320, epoch: 71.6923, train loss: 2.7188, grad_norm: 0.39, 566.51ms/step, 677.84samples/sec\n",
      "step 9360, epoch: 72.0000, train loss: 2.7031, grad_norm: 0.38, 576.54ms/step, 666.04samples/sec\n",
      "step 9400, epoch: 72.3077, train loss: 2.5938, grad_norm: 0.36, 571.07ms/step, 672.42samples/sec\n",
      "step 9440, epoch: 72.6154, train loss: 2.6094, grad_norm: 0.37, 566.08ms/step, 678.35samples/sec\n",
      "step 9480, epoch: 72.9231, train loss: 2.5469, grad_norm: 0.33, 571.21ms/step, 672.26samples/sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(transformer\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()    \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m steps_log \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:227\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         state_steps,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:767\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 767\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:529\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    526\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_params, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_lerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n\u001b[1;32m    532\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcmul_(\n\u001b[1;32m    533\u001b[0m     device_exp_avg_sqs, device_grads, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2\n\u001b[1;32m    534\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if log_wandb: \n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    wandb.init(project=\"Hana\", name=f\"Z-{model_size / 1e6:.2f}M_CIFAR10-128_LR-{lr}_BS-{bs}_TS-{timesteps_training}_my3090\").log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\") or path.endswith(\".json\"))\n",
    "\n",
    "step = 0\n",
    "last_step_time = time.time()\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for labels, latents, prompts_encoded, prompts_atnmask in dataloader:\n",
    "        noise = torch.randn_like(latents)\n",
    "        t = torch.randint(1, timesteps_training + 1, (latents.size(0),)).to(device)\n",
    "        tperc = t.view([latents.size(0), *([1] * len(latents.shape[1:]))])/timesteps_training\n",
    "        latents = latents * dcae_scalingf\n",
    "        latents_noisy = (1 - tperc) * latents + tperc * noise # (1-noise_level) * latent + noise_level * noise\n",
    "        noise_pred = transformer(latents_noisy.to(dtype), prompts_encoded, t, prompts_atnmask).sample\n",
    "    \n",
    "        loss = F.mse_loss(noise_pred, noise - latents)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(transformer.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()    \n",
    "        \n",
    "        if step % steps_log == 0:\n",
    "            loss_train = loss.item()\n",
    "            step_time = (time.time() - last_step_time) / steps_log * 1000\n",
    "            sample_tp = bs * steps_log / (time.time() - last_step_time)\n",
    "            print(f\"step {step}, epoch: {step / steps_epoch:.4f}, train loss: {loss_train:.4f}, grad_norm: {grad_norm:.2f}, {step_time:.2f}ms/step, {sample_tp:.2f}samples/sec\")\n",
    "            if log_wandb: wandb.log({\"loss_train\": loss_train, \"grad_norm\": grad_norm, \"step_time\": step_time, \"step\": step, \"sample_tp\": sample_tp, \"sample_count\": step * bs, \"epoch\": step / steps_epoch})\n",
    "            last_step_time = time.time()\n",
    "    \n",
    "        if step % steps_eval == 0:\n",
    "            transformer.eval()\n",
    "            loss_eval = eval_loss(data_val)\n",
    "            images_eval = [generate(p) for p in tqdm([cifar10_labels[k] for k in cifar10_labels], \"eval_images\")]\n",
    "            clipscore = eval_clipscore(images_eval)\n",
    "            print(f\"step {step}, eval loss: {loss_eval:.4f}, clipscore: {clipscore:.2f}\")\n",
    "            if log_wandb: wandb.log({\"loss_eval\": loss_eval, \"clipscore\": clipscore, \"images_eval\": wandb.Image(make_grid(images_eval, 2, 5)), \"step\": step, \"sample_count\": step * bs, \"epoch\": step / steps_epoch})\n",
    "            transformer.train()\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ec19c-1862-4c89-b46d-6206fd4f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.push_to_hub(f\"g-ronimo/hana-alpha14_cifar10-128_TS-{timesteps_training}_{epochs}e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429d2e8-546c-431d-a8a7-1391011d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !runpodctl remove pod $RUNPOD_POD_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
