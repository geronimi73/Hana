{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8e2b3c51-c463-4e86-850b-09cccf16a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ed42fff0-2d43-419f-94b8-c1f7d087b295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    0.5: Dataset({\n",
       "        features: ['img'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    1.0: Dataset({\n",
       "        features: ['img'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "    1.5: Dataset({\n",
       "        features: ['img'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_lists = {}\n",
    "img_id=0\n",
    "for ar in [0.5, 1.0, 1.5]:\n",
    "    if not ar in ds_lists:\n",
    "        ds_lists[ar]=[]    \n",
    "        for _ in range(round(4*ar)):\n",
    "            ds_lists[ar].append(dict(img=f\"image {img_id}, ar {ar}\"))\n",
    "            img_id+=1\n",
    "\n",
    "ds = DatasetDict({\n",
    "    str(split): Dataset.from_list(ds_lists[split]) \n",
    "    for split in ds_lists\n",
    "})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c4ceb45e-f83e-46b9-8460-2af4c0cb3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeBatchingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset wrapper that handles batching samples with different aspect ratios.\n",
    "    \n",
    "    Creates separate dataloaders for each aspect ratio (split) and cycles through them\n",
    "    in round-robin fashion. Ensures all samples in a batch have the same aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        hf_dataset: HuggingFace DatasetDict with splits representing different aspect ratios\n",
    "        splits: List of split names to use from the dataset\n",
    "        batch_size: Number of samples per batch (default: 8)\n",
    "        seed: Random seed for samplers (default: 42)\n",
    "    \n",
    "    Yields:\n",
    "        Tuples of (split_name, batch_data) where each batch contains samples\n",
    "        of the same aspect ratio.\n",
    "    \"\"\"\n",
    "    def __init__(self, hf_dataset, splits, batch_size=8):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.splits = splits  # each split is one aspect ratio\n",
    "        self.dataloaders = {}\n",
    "        \n",
    "        # Create a dataloader for each split (=aspect ratio)\n",
    "        for split in splits:\n",
    "            sampler = torch.utils.data.RandomSampler(hf_dataset[split])\n",
    "            self.dataloaders[split] = torch.utils.data.DataLoader(\n",
    "                hf_dataset[split], sampler=sampler, batch_size=batch_size\n",
    "            )\n",
    "    \n",
    "    def __iter__(self):\n",
    "        # Reset iterators at the beginning of each epoch\n",
    "        iterators = { split: iter(dataloader) for split, dataloader in self.dataloaders.items() }\n",
    "        active_dataloaders = set(self.splits)  # Track exhausted dataloaders\n",
    "        current_split_index = -1\n",
    "        \n",
    "        while active_dataloaders:\n",
    "            # Round robin: change split on every iteration (=after every batch OR after we unsucc. tried to get a batch) \n",
    "            current_split_index = (current_split_index + 1) % len(self.splits)\n",
    "            split = self.splits[current_split_index]\n",
    "\n",
    "            # Skip if this dataloader is exhausted\n",
    "            if split not in active_dataloaders: continue\n",
    "            \n",
    "            # Try to get the next batch\n",
    "            try:\n",
    "                batch = next(iterators[split])\n",
    "                yield split, batch\n",
    "            # dataloader is exhausted\n",
    "            except StopIteration: active_dataloaders.remove(split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(dataloader) for dataloader in self.dataloaders.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "50a81350-4513-40e5-8237-7df0879e35ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Processing batch with aspect ratio: 0.5\n",
      "{'img': ['image 1, ar 0.5', 'image 0, ar 0.5']}\n",
      "Processing batch with aspect ratio: 1.0\n",
      "{'img': ['image 2, ar 1.0', 'image 5, ar 1.0', 'image 3, ar 1.0']}\n",
      "Processing batch with aspect ratio: 1.5\n",
      "{'img': ['image 10, ar 1.5', 'image 8, ar 1.5', 'image 6, ar 1.5']}\n",
      "Processing batch with aspect ratio: 1.0\n",
      "{'img': ['image 4, ar 1.0']}\n",
      "Processing batch with aspect ratio: 1.5\n",
      "{'img': ['image 7, ar 1.5', 'image 11, ar 1.5', 'image 9, ar 1.5']}\n",
      "processed 12 samples\n"
     ]
    }
   ],
   "source": [
    "shape_dataset = ShapeBatchingDataset(\n",
    "    hf_dataset=ds, splits=[\"0.5\", \"1.0\", \"1.5\"], batch_size=3\n",
    ")\n",
    "\n",
    "print(len(shape_dataset))\n",
    "\n",
    "# Iterate through batches\n",
    "samples = 0 \n",
    "for split, batch in shape_dataset:\n",
    "    print(f\"Processing batch with aspect ratio: {split}\")\n",
    "    print(batch)\n",
    "    samples += len(batch[\"img\"])\n",
    "print(\"processed\",samples,\"samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
