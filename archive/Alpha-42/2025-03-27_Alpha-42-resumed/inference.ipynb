{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aafd25-7923-4182-a0b2-f1b09dbe2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F, random, wandb, time\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from diffusers import AutoencoderDC, SanaTransformer2DModel\n",
    "from diffusers.schedulers import FlowMatchEulerDiscreteScheduler\n",
    "from transformers import AutoModel, AutoTokenizer, set_seed, Siglip2TextModel\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "from utils import (\n",
    "    linear_multistep_coeff,\n",
    "    pil_add_text, \n",
    "    latent_to_PIL, \n",
    "    make_grid, \n",
    "    encode_prompt, \n",
    "    dcae_scalingf, \n",
    "    free_memory, \n",
    "    generate,\n",
    "    generate_lms,\n",
    ")\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6877b-ca35-4fcb-8513-633d9be0ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.bfloat16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "transformer = SanaTransformer2DModel.from_pretrained(\n",
    "    \"./cp-e76\"\n",
    ").to(device).to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a479b15-78e2-4b9b-ab16-0b1b693ec159",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = AutoModel.from_pretrained(\"HuggingFaceTB/SmolLM2-360M\", torch_dtype=dtype).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-360M\", torch_dtype=dtype)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "dcae = AutoencoderDC.from_pretrained(\"Efficient-Large-Model/Sana_600M_1024px_diffusers\", subfolder=\"vae\", torch_dtype=dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda98e81-31ce-4e7c-ab9c-8a3b64334ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"text_encoder parameters: {sum(p.numel() for p in text_encoder.parameters()) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2fb73-e5cd-444f-8e82-2a621e6e3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_components = dict(\n",
    "    transformer=transformer,\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder=text_encoder,\n",
    "    dcae=dcae,\n",
    ")\n",
    "inference_config = dict(\n",
    "    # guidance_scale=4,\n",
    "    latent_dim=[1, 32, 8, 12],\n",
    "    latent_seed = 92216724,\n",
    "    num_steps=20\n",
    ")\n",
    "\n",
    "# prompt = \"a photo of a red train in the mountains\"\n",
    "# prompt = \"a white cat with purple ears\"\n",
    "prompt = \"A polar bear sitting in a red car on the beach\"\n",
    "# prompt = \"a beautiful field of flowers\"\n",
    "# prompt = \"a man and a woman on the beach \"\n",
    "# prompt = \"a dog in the swimming pool\"\n",
    "# prompt = \"a black car in the middle of a beautiful endless field of white flowers\"\n",
    "\n",
    "make_grid([\n",
    "    generate(prompt, guidance_scale=2, **pipeline_components, **inference_config),\n",
    "    generate(prompt, guidance_scale=4, **pipeline_components, **inference_config),\n",
    "    generate(prompt, guidance_scale=5, **pipeline_components, **inference_config),\n",
    "    generate(prompt, guidance_scale=6, **pipeline_components, **inference_config),\n",
    "    generate(prompt, guidance_scale=7, **pipeline_components, **inference_config),\n",
    "    generate(prompt, guidance_scale=10, **pipeline_components, **inference_config),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f19c48-04ef-4602-85d2-24315164b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_components = dict(\n",
    "    transformer=transformer,\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder=text_encoder,\n",
    "    dcae=dcae,\n",
    ")\n",
    "inference_config = dict(\n",
    "    guidance_scale=5,\n",
    "    latent_dim=[1, 32, 15, 20],\n",
    "    latent_seed = 92216724,\n",
    "    num_steps=20\n",
    ")\n",
    "\n",
    "prompt = \"a beautiful mountain landscape showing a bunch of people\"\n",
    "\n",
    "img = generate(prompt, **pipeline_components, **inference_config)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51453813-5282-4411-bd45-8ef20f5306d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33973ea2-f72b-45cb-84bf-56f90c60c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_components = dict(\n",
    "    transformer=transformer,\n",
    "    tokenizer=tokenizer,\n",
    "    text_encoder=text_encoder,\n",
    "    dcae=dcae,\n",
    ")\n",
    "inference_config = dict(\n",
    "    guidance_scale=5,\n",
    "    latent_dim=[1, 32, 8, 8],\n",
    "    # latent_seed = 9221672424,\n",
    "    num_steps=20\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    \"a dog\",\n",
    "    \"a dog with blue eyes\",\n",
    "    \"a dog on the beach\",\n",
    "    \"a dog in the swimming pool\",\n",
    "    \"a shark in the ocean\",\n",
    "    \"a blue airplane taking off at the airport\",\n",
    "    \"a bird in the swimming pool\",\n",
    "    \"a beautiful snowy mountain landscape\",\n",
    "    \"a woman\",\n",
    "    \"a woman and her dog on the beach\",\n",
    "    \"a woman eating a cheeseburger\",\n",
    "    \"an astronaut riding a rainbow unicorn\",\n",
    "]\n",
    "\n",
    "num_imgs_per_label = len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc737b72-e732-45f2-aee3-4f5429fb77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {p:[] for p in prompts}\n",
    "x0s = {p: \n",
    "       [ {step:[] for step in range(inference_config[\"num_steps\"])} \n",
    "        for _ in range(num_imgs_per_label) ]\n",
    "    for p in prompts\n",
    "}\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    imgs_xps_prompt = [\n",
    "        generate(prompt, return_xps=True, **pipeline_components, **inference_config)\n",
    "        for _ in range(num_imgs_per_label)\n",
    "    ]\n",
    "    images[prompt] = [img_xps[0] for img_xps in imgs_xps_prompt] # imgs_xps_prompt[0]=image, imgs_xps_prompt[1]=list of x0s \n",
    "    for img_no in range(num_imgs_per_label):\n",
    "        for step in range(inference_config[\"num_steps\"]):\n",
    "            x0s[prompt][img_no][step] = imgs_xps_prompt[img_no][1][step]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97ac52-f2b6-4a18-8272-814d81a84a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gallery of all denoised images\n",
    "gallery = make_grid([\n",
    "    pil_add_text( make_grid(images[p]), p, font_size=40, position=(0,0))\n",
    "    for p in prompts\n",
    "], len(prompts), 1)\n",
    "gallery.save(\"output.png\")\n",
    "\n",
    "gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf794ec3-5195-44f3-98b9-460f80972da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of galleries of x predictions, one item per step\n",
    "gallery_x0s = [\n",
    "    make_grid([\n",
    "        pil_add_text(\n",
    "            make_grid([ x0s[prompt][img_no][step] for img_no in range(num_imgs_per_label)])\n",
    "        , prompt)\n",
    "        for prompt in prompts\n",
    "    ], len(prompts), 1)\n",
    "    for step in range(inference_config[\"num_steps\"])\n",
    "]\n",
    "\n",
    "# original size\n",
    "gif_anim = deepcopy(gallery_x0s)\n",
    "gif_anim += [gif_anim[-1]]*15\n",
    "\n",
    "gif_anim[-1].save(\"output.gif\", save_all=True, append_images=gif_anim[1:-1], duration=100, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bcfdcb-bace-4de1-85b7-79e8804025ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i output.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670f205-40c9-469e-a691-35f59b03f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# half size\n",
    "gif_anim = deepcopy(gallery_x0s)\n",
    "gif_anim = [i.resize((int(i.width//2.5), int(i.height//2.5))) for i in gif_anim]\n",
    "gif_anim += [gif_anim[-1]]*15\n",
    "\n",
    "gif_anim[-1].save(\"output_half.gif\", save_all=True, append_images=gif_anim[1:-1], duration=100, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1686ddf-45be-4f8f-b916-8c40b8fa6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i output_half.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" output_half.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed496a3-e93b-4665-94dc-48538b0f760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_selection = [\n",
    "    prompts[0],\n",
    "    prompts[2],\n",
    "    prompts[4],\n",
    "    prompts[6],\n",
    "    prompts[7],\n",
    "    prompts[8],\n",
    "    prompts[9],\n",
    "    prompts[10],\n",
    "]\n",
    "prompt_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75563f6-57ae-46c0-9219-44f8623a17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 prediction gallery for selected prompts\n",
    "num_inf_steps = 20\n",
    "num_imgs_per_label = len(prompt_selection)\n",
    "\n",
    "gallery_x0s = [\n",
    "    make_grid([\n",
    "        pil_add_text(\n",
    "            make_grid([ x0s[prompt][img_no][step] for img_no in range(num_imgs_per_label)])\n",
    "        , prompt, font_size=40, stroke_width=2, position=(2,0))\n",
    "        for prompt in prompt_selection\n",
    "    ], len(prompt_selection), 1)\n",
    "    for step in range(num_inf_steps)\n",
    "]\n",
    "\n",
    "# half size\n",
    "gif_anim = deepcopy(gallery_x0s)\n",
    "gif_anim = [i.resize((int(i.width//2), int(i.height//2))) for i in gif_anim]\n",
    "gif_anim += [gif_anim[-1]]*15\n",
    "\n",
    "gif_anim[-1].save(\"output_selected.gif\", save_all=True, append_images=gif_anim[1:-1], duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cf2df-67c3-4690-b1f6-a256f5ba8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ffmpeg -i output_selected.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" output_selected.mp4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
