{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610d29a7-90d0-4aea-a535-56f2ee26145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers accelerate datasets diffusers Pillow==9.4.0 wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a076321-f9eb-4f7d-b3fd-a0b0b418d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from local_secrets import hf_token, wandb_key\n",
    "# from huggingface_hub import login\n",
    "# import wandb\n",
    "\n",
    "# login(token=hf_token)\n",
    "# wandb.login(key=wandb_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60395d2d-a5f3-432d-9d29-cc3e6adf8774",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mrandom\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderDC, SanaTransformer2DModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschedulers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlowMatchEulerDiscreteScheduler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gemma2Model, GemmaTokenizerFast, AutoModel, AutoTokenizer\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py:911\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    910\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m--> 911\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py:910\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    908\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 910\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py:920\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    923\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    924\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    925\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_asym_kl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsymmetricAutoencoderKL\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_dc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderDC\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_kl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKL\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_asym_kl.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKLOutput\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelMixin\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecoderOutput, DiagonalGaussianDistribution, Encoder, MaskConditionDecoder\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAsymmetricAutoencoderKL\u001b[39;00m(ModelMixin, ConfigMixin):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Designing a Better Asymmetric VQGAN for StableDiffusion https://arxiv.org/abs/2306.04632 . A VAE model with KL loss\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    for encoding images into latents and decoding latent representations into images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m            Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) paper.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/vae.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_activation\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpatialNorm\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_blocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     AutoencoderTinyBlock,\n\u001b[1;32m     27\u001b[0m     UNetMidBlock2D,\n\u001b[1;32m     28\u001b[0m     get_down_block,\n\u001b[1;32m     29\u001b[0m     get_up_block,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEncoderOutput\u001b[39;00m(BaseOutput):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Output of encoding method.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m            The encoded latent.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_1d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet1DModel\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet2DModel\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_condition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet2DConditionModel\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_3d_condition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet3DConditionModel\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianFourierProjection, TimestepEmbedding, Timesteps\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelMixin\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_blocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNetMidBlock2D, get_down_block, get_up_block\n\u001b[1;32m     27\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUNet2DOutput\u001b[39;00m(BaseOutput):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    The output of [`UNet2DModel`].\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m            The hidden states output from the last layer of the model.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py:36\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaGroupNorm\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     Downsample2D,\n\u001b[1;32m     28\u001b[0m     FirDownsample2D,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     Upsample2D,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdual_transformer_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DualTransformer2DModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer2DModel\n\u001b[1;32m     40\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauraflow_transformer_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AuraFlowTransformer2DModel\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcogvideox_transformer_3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CogVideoXTransformer3DModel\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdit_transformer_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiTTransformer2DModel\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdual_transformer_2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DualTransformer2DModel\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/cogvideox_transformer_3d.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigMixin, register_to_config\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m USE_PEFT_BACKEND, is_torch_version, logging, scale_lora_layers, unscale_lora_layers\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maybe_allow_in_graph\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py:910\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    908\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 910\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/import_utils.py:920\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    923\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    924\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    925\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/loaders/peft.py:38\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MIN_PEFT_VERSION,\n\u001b[1;32m     26\u001b[0m     USE_PEFT_BACKEND,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     set_weights_and_activate_adapters,\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fetch_state_dict, _func_optionally_disable_offloading\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_loader_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _maybe_expand_lora_scales\n\u001b[1;32m     42\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/loaders/lora_base.py:51\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     USE_PEFT_BACKEND,\n\u001b[1;32m     30\u001b[0m     _get_model_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     set_weights_and_activate_adapters,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_transformers_available():\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_encoder_attn_modules, text_encoder_mlp_modules\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_peft_available():\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1819\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:62\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     Conv1D,\n\u001b[1;32m     54\u001b[0m     apply_chunking_to_forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     translate_to_torch_parallel_style,\n\u001b[1;32m     61\u001b[0m )\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_module_from_name\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msafetensors_conversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_conversion\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/__init__.py:14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, AutoQuantizationConfig\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfQuantizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     AqlmConfig,\n\u001b[1;32m     20\u001b[0m     AwqConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     VptqConfig,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizer_aqlm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AqlmHfQuantizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     albert,\n\u001b[1;32m     17\u001b[0m     align,\n\u001b[1;32m     18\u001b[0m     altclip,\n\u001b[1;32m     19\u001b[0m     aria,\n\u001b[1;32m     20\u001b[0m     audio_spectrogram_transformer,\n\u001b[1;32m     21\u001b[0m     auto,\n\u001b[1;32m     22\u001b[0m     autoformer,\n\u001b[1;32m     23\u001b[0m     bamba,\n\u001b[1;32m     24\u001b[0m     bark,\n\u001b[1;32m     25\u001b[0m     bart,\n\u001b[1;32m     26\u001b[0m     barthez,\n\u001b[1;32m     27\u001b[0m     bartpho,\n\u001b[1;32m     28\u001b[0m     beit,\n\u001b[1;32m     29\u001b[0m     bert,\n\u001b[1;32m     30\u001b[0m     bert_generation,\n\u001b[1;32m     31\u001b[0m     bert_japanese,\n\u001b[1;32m     32\u001b[0m     bertweet,\n\u001b[1;32m     33\u001b[0m     big_bird,\n\u001b[1;32m     34\u001b[0m     bigbird_pegasus,\n\u001b[1;32m     35\u001b[0m     biogpt,\n\u001b[1;32m     36\u001b[0m     bit,\n\u001b[1;32m     37\u001b[0m     blenderbot,\n\u001b[1;32m     38\u001b[0m     blenderbot_small,\n\u001b[1;32m     39\u001b[0m     blip,\n\u001b[1;32m     40\u001b[0m     blip_2,\n\u001b[1;32m     41\u001b[0m     bloom,\n\u001b[1;32m     42\u001b[0m     bridgetower,\n\u001b[1;32m     43\u001b[0m     bros,\n\u001b[1;32m     44\u001b[0m     byt5,\n\u001b[1;32m     45\u001b[0m     camembert,\n\u001b[1;32m     46\u001b[0m     canine,\n\u001b[1;32m     47\u001b[0m     chameleon,\n\u001b[1;32m     48\u001b[0m     chinese_clip,\n\u001b[1;32m     49\u001b[0m     clap,\n\u001b[1;32m     50\u001b[0m     clip,\n\u001b[1;32m     51\u001b[0m     clipseg,\n\u001b[1;32m     52\u001b[0m     clvp,\n\u001b[1;32m     53\u001b[0m     code_llama,\n\u001b[1;32m     54\u001b[0m     codegen,\n\u001b[1;32m     55\u001b[0m     cohere,\n\u001b[1;32m     56\u001b[0m     cohere2,\n\u001b[1;32m     57\u001b[0m     colpali,\n\u001b[1;32m     58\u001b[0m     conditional_detr,\n\u001b[1;32m     59\u001b[0m     convbert,\n\u001b[1;32m     60\u001b[0m     convnext,\n\u001b[1;32m     61\u001b[0m     convnextv2,\n\u001b[1;32m     62\u001b[0m     cpm,\n\u001b[1;32m     63\u001b[0m     cpmant,\n\u001b[1;32m     64\u001b[0m     ctrl,\n\u001b[1;32m     65\u001b[0m     cvt,\n\u001b[1;32m     66\u001b[0m     dac,\n\u001b[1;32m     67\u001b[0m     data2vec,\n\u001b[1;32m     68\u001b[0m     dbrx,\n\u001b[1;32m     69\u001b[0m     deberta,\n\u001b[1;32m     70\u001b[0m     deberta_v2,\n\u001b[1;32m     71\u001b[0m     decision_transformer,\n\u001b[1;32m     72\u001b[0m     deformable_detr,\n\u001b[1;32m     73\u001b[0m     deit,\n\u001b[1;32m     74\u001b[0m     deprecated,\n\u001b[1;32m     75\u001b[0m     depth_anything,\n\u001b[1;32m     76\u001b[0m     detr,\n\u001b[1;32m     77\u001b[0m     dialogpt,\n\u001b[1;32m     78\u001b[0m     diffllama,\n\u001b[1;32m     79\u001b[0m     dinat,\n\u001b[1;32m     80\u001b[0m     dinov2,\n\u001b[1;32m     81\u001b[0m     dinov2_with_registers,\n\u001b[1;32m     82\u001b[0m     distilbert,\n\u001b[1;32m     83\u001b[0m     dit,\n\u001b[1;32m     84\u001b[0m     donut,\n\u001b[1;32m     85\u001b[0m     dpr,\n\u001b[1;32m     86\u001b[0m     dpt,\n\u001b[1;32m     87\u001b[0m     efficientnet,\n\u001b[1;32m     88\u001b[0m     electra,\n\u001b[1;32m     89\u001b[0m     emu3,\n\u001b[1;32m     90\u001b[0m     encodec,\n\u001b[1;32m     91\u001b[0m     encoder_decoder,\n\u001b[1;32m     92\u001b[0m     ernie,\n\u001b[1;32m     93\u001b[0m     esm,\n\u001b[1;32m     94\u001b[0m     falcon,\n\u001b[1;32m     95\u001b[0m     falcon_mamba,\n\u001b[1;32m     96\u001b[0m     fastspeech2_conformer,\n\u001b[1;32m     97\u001b[0m     flaubert,\n\u001b[1;32m     98\u001b[0m     flava,\n\u001b[1;32m     99\u001b[0m     fnet,\n\u001b[1;32m    100\u001b[0m     focalnet,\n\u001b[1;32m    101\u001b[0m     fsmt,\n\u001b[1;32m    102\u001b[0m     funnel,\n\u001b[1;32m    103\u001b[0m     fuyu,\n\u001b[1;32m    104\u001b[0m     gemma,\n\u001b[1;32m    105\u001b[0m     gemma2,\n\u001b[1;32m    106\u001b[0m     git,\n\u001b[1;32m    107\u001b[0m     glm,\n\u001b[1;32m    108\u001b[0m     glpn,\n\u001b[1;32m    109\u001b[0m     gpt2,\n\u001b[1;32m    110\u001b[0m     gpt_bigcode,\n\u001b[1;32m    111\u001b[0m     gpt_neo,\n\u001b[1;32m    112\u001b[0m     gpt_neox,\n\u001b[1;32m    113\u001b[0m     gpt_neox_japanese,\n\u001b[1;32m    114\u001b[0m     gpt_sw3,\n\u001b[1;32m    115\u001b[0m     gptj,\n\u001b[1;32m    116\u001b[0m     granite,\n\u001b[1;32m    117\u001b[0m     granitemoe,\n\u001b[1;32m    118\u001b[0m     grounding_dino,\n\u001b[1;32m    119\u001b[0m     groupvit,\n\u001b[1;32m    120\u001b[0m     herbert,\n\u001b[1;32m    121\u001b[0m     hiera,\n\u001b[1;32m    122\u001b[0m     hubert,\n\u001b[1;32m    123\u001b[0m     ibert,\n\u001b[1;32m    124\u001b[0m     idefics,\n\u001b[1;32m    125\u001b[0m     idefics2,\n\u001b[1;32m    126\u001b[0m     idefics3,\n\u001b[1;32m    127\u001b[0m     ijepa,\n\u001b[1;32m    128\u001b[0m     imagegpt,\n\u001b[1;32m    129\u001b[0m     informer,\n\u001b[1;32m    130\u001b[0m     instructblip,\n\u001b[1;32m    131\u001b[0m     instructblipvideo,\n\u001b[1;32m    132\u001b[0m     jamba,\n\u001b[1;32m    133\u001b[0m     jetmoe,\n\u001b[1;32m    134\u001b[0m     kosmos2,\n\u001b[1;32m    135\u001b[0m     layoutlm,\n\u001b[1;32m    136\u001b[0m     layoutlmv2,\n\u001b[1;32m    137\u001b[0m     layoutlmv3,\n\u001b[1;32m    138\u001b[0m     layoutxlm,\n\u001b[1;32m    139\u001b[0m     led,\n\u001b[1;32m    140\u001b[0m     levit,\n\u001b[1;32m    141\u001b[0m     lilt,\n\u001b[1;32m    142\u001b[0m     llama,\n\u001b[1;32m    143\u001b[0m     llava,\n\u001b[1;32m    144\u001b[0m     llava_next,\n\u001b[1;32m    145\u001b[0m     llava_next_video,\n\u001b[1;32m    146\u001b[0m     llava_onevision,\n\u001b[1;32m    147\u001b[0m     longformer,\n\u001b[1;32m    148\u001b[0m     longt5,\n\u001b[1;32m    149\u001b[0m     luke,\n\u001b[1;32m    150\u001b[0m     lxmert,\n\u001b[1;32m    151\u001b[0m     m2m_100,\n\u001b[1;32m    152\u001b[0m     mamba,\n\u001b[1;32m    153\u001b[0m     mamba2,\n\u001b[1;32m    154\u001b[0m     marian,\n\u001b[1;32m    155\u001b[0m     markuplm,\n\u001b[1;32m    156\u001b[0m     mask2former,\n\u001b[1;32m    157\u001b[0m     maskformer,\n\u001b[1;32m    158\u001b[0m     mbart,\n\u001b[1;32m    159\u001b[0m     mbart50,\n\u001b[1;32m    160\u001b[0m     megatron_bert,\n\u001b[1;32m    161\u001b[0m     megatron_gpt2,\n\u001b[1;32m    162\u001b[0m     mgp_str,\n\u001b[1;32m    163\u001b[0m     mimi,\n\u001b[1;32m    164\u001b[0m     mistral,\n\u001b[1;32m    165\u001b[0m     mixtral,\n\u001b[1;32m    166\u001b[0m     mllama,\n\u001b[1;32m    167\u001b[0m     mluke,\n\u001b[1;32m    168\u001b[0m     mobilebert,\n\u001b[1;32m    169\u001b[0m     mobilenet_v1,\n\u001b[1;32m    170\u001b[0m     mobilenet_v2,\n\u001b[1;32m    171\u001b[0m     mobilevit,\n\u001b[1;32m    172\u001b[0m     mobilevitv2,\n\u001b[1;32m    173\u001b[0m     modernbert,\n\u001b[1;32m    174\u001b[0m     moonshine,\n\u001b[1;32m    175\u001b[0m     moshi,\n\u001b[1;32m    176\u001b[0m     mpnet,\n\u001b[1;32m    177\u001b[0m     mpt,\n\u001b[1;32m    178\u001b[0m     mra,\n\u001b[1;32m    179\u001b[0m     mt5,\n\u001b[1;32m    180\u001b[0m     musicgen,\n\u001b[1;32m    181\u001b[0m     musicgen_melody,\n\u001b[1;32m    182\u001b[0m     mvp,\n\u001b[1;32m    183\u001b[0m     myt5,\n\u001b[1;32m    184\u001b[0m     nemotron,\n\u001b[1;32m    185\u001b[0m     nllb,\n\u001b[1;32m    186\u001b[0m     nllb_moe,\n\u001b[1;32m    187\u001b[0m     nougat,\n\u001b[1;32m    188\u001b[0m     nystromformer,\n\u001b[1;32m    189\u001b[0m     olmo,\n\u001b[1;32m    190\u001b[0m     olmo2,\n\u001b[1;32m    191\u001b[0m     olmoe,\n\u001b[1;32m    192\u001b[0m     omdet_turbo,\n\u001b[1;32m    193\u001b[0m     oneformer,\n\u001b[1;32m    194\u001b[0m     openai,\n\u001b[1;32m    195\u001b[0m     opt,\n\u001b[1;32m    196\u001b[0m     owlv2,\n\u001b[1;32m    197\u001b[0m     owlvit,\n\u001b[1;32m    198\u001b[0m     paligemma,\n\u001b[1;32m    199\u001b[0m     patchtsmixer,\n\u001b[1;32m    200\u001b[0m     patchtst,\n\u001b[1;32m    201\u001b[0m     pegasus,\n\u001b[1;32m    202\u001b[0m     pegasus_x,\n\u001b[1;32m    203\u001b[0m     perceiver,\n\u001b[1;32m    204\u001b[0m     persimmon,\n\u001b[1;32m    205\u001b[0m     phi,\n\u001b[1;32m    206\u001b[0m     phi3,\n\u001b[1;32m    207\u001b[0m     phimoe,\n\u001b[1;32m    208\u001b[0m     phobert,\n\u001b[1;32m    209\u001b[0m     pix2struct,\n\u001b[1;32m    210\u001b[0m     pixtral,\n\u001b[1;32m    211\u001b[0m     plbart,\n\u001b[1;32m    212\u001b[0m     poolformer,\n\u001b[1;32m    213\u001b[0m     pop2piano,\n\u001b[1;32m    214\u001b[0m     prophetnet,\n\u001b[1;32m    215\u001b[0m     pvt,\n\u001b[1;32m    216\u001b[0m     pvt_v2,\n\u001b[1;32m    217\u001b[0m     qwen2,\n\u001b[1;32m    218\u001b[0m     qwen2_audio,\n\u001b[1;32m    219\u001b[0m     qwen2_moe,\n\u001b[1;32m    220\u001b[0m     qwen2_vl,\n\u001b[1;32m    221\u001b[0m     rag,\n\u001b[1;32m    222\u001b[0m     recurrent_gemma,\n\u001b[1;32m    223\u001b[0m     reformer,\n\u001b[1;32m    224\u001b[0m     regnet,\n\u001b[1;32m    225\u001b[0m     rembert,\n\u001b[1;32m    226\u001b[0m     resnet,\n\u001b[1;32m    227\u001b[0m     roberta,\n\u001b[1;32m    228\u001b[0m     roberta_prelayernorm,\n\u001b[1;32m    229\u001b[0m     roc_bert,\n\u001b[1;32m    230\u001b[0m     roformer,\n\u001b[1;32m    231\u001b[0m     rt_detr,\n\u001b[1;32m    232\u001b[0m     rwkv,\n\u001b[1;32m    233\u001b[0m     sam,\n\u001b[1;32m    234\u001b[0m     seamless_m4t,\n\u001b[1;32m    235\u001b[0m     seamless_m4t_v2,\n\u001b[1;32m    236\u001b[0m     segformer,\n\u001b[1;32m    237\u001b[0m     seggpt,\n\u001b[1;32m    238\u001b[0m     sew,\n\u001b[1;32m    239\u001b[0m     sew_d,\n\u001b[1;32m    240\u001b[0m     siglip,\n\u001b[1;32m    241\u001b[0m     speech_encoder_decoder,\n\u001b[1;32m    242\u001b[0m     speech_to_text,\n\u001b[1;32m    243\u001b[0m     speecht5,\n\u001b[1;32m    244\u001b[0m     splinter,\n\u001b[1;32m    245\u001b[0m     squeezebert,\n\u001b[1;32m    246\u001b[0m     stablelm,\n\u001b[1;32m    247\u001b[0m     starcoder2,\n\u001b[1;32m    248\u001b[0m     superpoint,\n\u001b[1;32m    249\u001b[0m     swiftformer,\n\u001b[1;32m    250\u001b[0m     swin,\n\u001b[1;32m    251\u001b[0m     swin2sr,\n\u001b[1;32m    252\u001b[0m     swinv2,\n\u001b[1;32m    253\u001b[0m     switch_transformers,\n\u001b[1;32m    254\u001b[0m     t5,\n\u001b[1;32m    255\u001b[0m     table_transformer,\n\u001b[1;32m    256\u001b[0m     tapas,\n\u001b[1;32m    257\u001b[0m     textnet,\n\u001b[1;32m    258\u001b[0m     time_series_transformer,\n\u001b[1;32m    259\u001b[0m     timesformer,\n\u001b[1;32m    260\u001b[0m     timm_backbone,\n\u001b[1;32m    261\u001b[0m     timm_wrapper,\n\u001b[1;32m    262\u001b[0m     trocr,\n\u001b[1;32m    263\u001b[0m     tvp,\n\u001b[1;32m    264\u001b[0m     udop,\n\u001b[1;32m    265\u001b[0m     umt5,\n\u001b[1;32m    266\u001b[0m     unispeech,\n\u001b[1;32m    267\u001b[0m     unispeech_sat,\n\u001b[1;32m    268\u001b[0m     univnet,\n\u001b[1;32m    269\u001b[0m     upernet,\n\u001b[1;32m    270\u001b[0m     video_llava,\n\u001b[1;32m    271\u001b[0m     videomae,\n\u001b[1;32m    272\u001b[0m     vilt,\n\u001b[1;32m    273\u001b[0m     vipllava,\n\u001b[1;32m    274\u001b[0m     vision_encoder_decoder,\n\u001b[1;32m    275\u001b[0m     vision_text_dual_encoder,\n\u001b[1;32m    276\u001b[0m     visual_bert,\n\u001b[1;32m    277\u001b[0m     vit,\n\u001b[1;32m    278\u001b[0m     vit_mae,\n\u001b[1;32m    279\u001b[0m     vit_msn,\n\u001b[1;32m    280\u001b[0m     vitdet,\n\u001b[1;32m    281\u001b[0m     vitmatte,\n\u001b[1;32m    282\u001b[0m     vitpose,\n\u001b[1;32m    283\u001b[0m     vitpose_backbone,\n\u001b[1;32m    284\u001b[0m     vits,\n\u001b[1;32m    285\u001b[0m     vivit,\n\u001b[1;32m    286\u001b[0m     wav2vec2,\n\u001b[1;32m    287\u001b[0m     wav2vec2_bert,\n\u001b[1;32m    288\u001b[0m     wav2vec2_conformer,\n\u001b[1;32m    289\u001b[0m     wav2vec2_phoneme,\n\u001b[1;32m    290\u001b[0m     wav2vec2_with_lm,\n\u001b[1;32m    291\u001b[0m     wavlm,\n\u001b[1;32m    292\u001b[0m     whisper,\n\u001b[1;32m    293\u001b[0m     x_clip,\n\u001b[1;32m    294\u001b[0m     xglm,\n\u001b[1;32m    295\u001b[0m     xlm,\n\u001b[1;32m    296\u001b[0m     xlm_roberta,\n\u001b[1;32m    297\u001b[0m     xlm_roberta_xl,\n\u001b[1;32m    298\u001b[0m     xlnet,\n\u001b[1;32m    299\u001b[0m     xmod,\n\u001b[1;32m    300\u001b[0m     yolos,\n\u001b[1;32m    301\u001b[0m     yoso,\n\u001b[1;32m    302\u001b[0m     zamba,\n\u001b[1;32m    303\u001b[0m     zoedepth,\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/__init__.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     32\u001b[0m _file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m _LazyModule(\u001b[38;5;18m__name__\u001b[39m, _file, \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m, module_spec\u001b[38;5;241m=\u001b[39m__spec__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:2236\u001b[0m, in \u001b[0;36mdefine_import_structure\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m IMPORT_STRUCTURE_T:\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;124;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[1;32m   2218\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;124;03m    The import structure is a dict defined with frozensets as keys, and dicts of strings to sets of objects.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2236\u001b[0m     import_structure \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spread_import_structure(import_structure)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py:2007\u001b[0m, in \u001b[0;36mcreate_import_structure_from_path\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m   2004\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, module_name), encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 2007\u001b[0m     file_content \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m module_name \u001b[38;5;241m=\u001b[39m module_name[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch, torch.nn.functional as F, random, wandb, time\n",
    "import torchvision.transforms as T\n",
    "from diffusers import AutoencoderDC, SanaTransformer2DModel\n",
    "from diffusers.schedulers import FlowMatchEulerDiscreteScheduler\n",
    "from transformers import Gemma2Model, GemmaTokenizerFast, AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import PIL_to_latent, latent_to_PIL, make_grid, encode_prompt, dcae_scalingf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a7f32-9159-48ca-9706-5b0566415fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Efficient-Large-Model/Sana_600M_1024px_diffusers\"\n",
    "dtype = torch.bfloat16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "transformer = SanaTransformer2DModel.from_config(\"transformer_Sana-7L-MBERT_config.json\", torch_dtype=dtype).to(device)\n",
    "dcae = AutoencoderDC.from_pretrained(model, subfolder=\"vae\", torch_dtype=dtype).to(device)\n",
    "\n",
    "text_encoder = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\", torch_dtype=dtype).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\", torch_dtype=dtype)\n",
    "# text_encoder = Gemma2Model.from_pretrained(model, subfolder=\"text_encoder\", torch_dtype=dtype).to(device)\n",
    "# tokenizer = GemmaTokenizerFast.from_pretrained(model, subfolder=\"tokenizer\", torch_dtype=dtype)\n",
    "\n",
    "scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(model, subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239874e-8912-4d43-a18b-bc764091aecc",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1606a-db13-4d7d-868e-52ed9d1f6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"g-ronimo/MNIST-latents_dc-ae-f32c32-sana-1.0\")\n",
    "\n",
    "mnist_labels_encoded={i: encode_prompt(str(i), tokenizer, text_encoder) for i in range(10)}\n",
    "\n",
    "len(mnist_labels_encoded[0]), mnist_labels_encoded[0][0].shape, mnist_labels_encoded[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb384ce1-f799-4cdd-8b0e-82c6422abde6",
   "metadata": {},
   "source": [
    "# Train data loaders and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ac467-1949-4e55-a4ea-5cd3dccfc72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(split=\"train\", sample_no=None, bs=1):\n",
    "    assert not (bs>1 and sample_no is not None), \"Can't have fixed sample with BS>1\" \n",
    "\n",
    "    idcs = [random.randint(0, len(ds[split])-1) for _ in range(bs)]\n",
    "    labels = [ds[split][idx][\"label\"] for idx in idcs]\n",
    "    latents = torch.cat([torch.Tensor(ds[split][idx][\"latent\"]) for idx in idcs])\n",
    "    prompts_encoded = torch.cat([mnist_labels_encoded[label][0] for label in labels])\n",
    "    prompts_atnmask = torch.cat([mnist_labels_encoded[label][1] for label in labels])\n",
    "    \n",
    "    return labels, latents.to(dtype).to(device), prompts_encoded, prompts_atnmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f601e-5383-4f49-8d6f-a534f42e63ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(num_samples=100):\n",
    "    losses = []\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        label, latent, prompt_encoded, prompt_atnmask = get_sample(\"test\", i)\n",
    "        noise = torch.randn(latent.shape).to(dtype).to(device)\n",
    "        timestep = scheduler.timesteps[random.randint(0, diffuser_timesteps-1)].unsqueeze(0).to(device)\n",
    "        # timestep = scheduler.timesteps[[random.randint(0, diffuser_timesteps-1) for _ in range(bs)]].to(device)\n",
    "        latent_noisy = scheduler.scale_noise(latent, timestep, noise)\n",
    "        with torch.no_grad():\n",
    "            noise_pred = transformer(latent_noisy, encoder_hidden_states = prompt_encoded, encoder_attention_mask = prompt_atnmask, timestep = timestep, return_dict=False)[0]\n",
    "        loss = F.mse_loss(noise_pred, noise - latent)\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses)/len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a90e44-c1c3-4d53-967d-8c3158bcf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, steps=10, latent_dim=[1, 32, 8, 8], latent_seed=42):\n",
    "    scheduler.set_timesteps(steps)\n",
    "    prompt_encoded, prompt_atnmask = encode_prompt(prompt, tokenizer, text_encoder)\n",
    "    latents = torch.randn(latent_dim, generator = torch.manual_seed(latent_seed) if latent_seed else None).to(dtype).to(device)\n",
    "\n",
    "    for t_idx in tqdm(range(steps)):\n",
    "        t = scheduler.timesteps[t_idx].unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            noise_pred = transformer(latents, encoder_hidden_states=prompt_encoded, timestep=t, encoder_attention_mask=prompt_atnmask, return_dict=False)[0]\n",
    "        latents = scheduler.step(noise_pred, t, latents, return_dict=False)[0]\n",
    "    return latent_to_PIL(latents / dcae_scalingf, dcae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894d9761-8eaa-4f23-bfad-cc5fa3ce923f",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02081c1d-e87c-438c-a54f-81d9704125da",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_wandb = True\n",
    "lr = 1e-4\n",
    "bs = 128\n",
    "epochs = 10\n",
    "diffuser_timesteps = 10\n",
    "\n",
    "steps_epoch = len(ds[\"train\"])\n",
    "steps_total = epochs * (steps_epoch // bs)\n",
    "steps_log = 20\n",
    "steps_eval = 200\n",
    "\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=lr)\n",
    "scheduler.set_timesteps(diffuser_timesteps)\n",
    "\n",
    "transformer=transformer.to(dtype).train()\n",
    "\n",
    "model_size = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {model_size / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e066f-ff72-4744-bf0c-a6fd090b4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_wandb: wandb.init(project=\"Hana\", name=f\"Z-{model_size / 1e6:.2f}M_MNIST_LR-{lr}_BS-{bs}_10-TS_MBERT-runpod4090\").log_code(\".\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\") or path.endswith(\".json\"))\n",
    "\n",
    "t_start, last_step_time = time.time(), time.time()\n",
    "sample_count, losses = 0, []\n",
    "\n",
    "for step in range(1, steps_total + 1):\n",
    "    transformer.train()\n",
    "    labels, latents, prompts_encoded, prompts_atnmask = get_sample(bs=bs)\n",
    "    noise = torch.randn_like(latents)\n",
    "    timesteps = scheduler.timesteps[[random.randint(0, diffuser_timesteps-1) for _ in range(bs)]].to(device)\n",
    "    latents_noisy = scheduler.scale_noise(latents, timesteps, noise)\n",
    "    \n",
    "    noise_pred = transformer(\n",
    "        latents_noisy, \n",
    "        encoder_hidden_states = prompts_encoded, \n",
    "        encoder_attention_mask = prompts_atnmask, \n",
    "        timestep = timesteps, \n",
    "        return_dict=False\n",
    "    )[0]\n",
    "\n",
    "    loss = F.mse_loss(noise_pred, noise - latents)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    sample_count = step * bs    \n",
    "    epoch = sample_count / steps_epoch\n",
    "    \n",
    "    if step >0 and step % steps_log == 0:\n",
    "        loss_train = sum(losses[-steps_log:])/steps_log\n",
    "        step_time = (time.time() - last_step_time) / steps_log * 1000\n",
    "        sample_tp = bs * steps_log / (time.time() - last_step_time)\n",
    "        print(f\"step {step}, epoch: {epoch:.4f}, train loss {loss_train:.4f}, {step_time:.2f}ms/step, {sample_tp:.2f}samples/sec\")\n",
    "        if log_wandb: wandb.log({\"loss_train\": loss_train, \"step_time\": step_time, \"step\": step, \"epoch\": epoch, \"sample_tp\": sample_tp, \"sample_count\": sample_count})\n",
    "        last_step_time = time.time()\n",
    "\n",
    "    if step >0 and step % steps_eval == 0:\n",
    "        transformer.eval()\n",
    "        loss_eval, images_eval = eval_loss(), make_grid([generate(str(p)) for p in range(10)], 2, 5)\n",
    "        print(f\"step {step}, eval loss {loss_eval:.4f}\")\n",
    "        if log_wandb: wandb.log({\"loss_eval\": loss_eval, \"images_eval\": wandb.Image(images_eval), \"step\": step, \"epoch\": epoch, \"sample_count\": sample_count})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ec19c-1862-4c89-b46d-6206fd4f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.push_to_hub(f\"g-ronimo/hana-small_MNIST-MODERNBERT-3e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429d2e8-546c-431d-a8a7-1391011d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !runpodctl remove pod $RUNPOD_POD_ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
